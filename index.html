<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Audio Recorder</title>
<style>
  body {
    font-family: Arial, sans-serif;
    text-align: center;
    margin: 0;
    padding: 0;
    display: flex;
    flex-direction: column;
    justify-content: center;
    align-items: center;
    height: 100vh;
    color: #333;

    /* Background Image Styling */
	background: url('background.webp') center center no-repeat;
	background-size: auto;
  }

  .microphone-container {
    position: relative;
    width: 150px;
    height: 150px;
    margin-bottom: 20px;
  }

  .microphone-icon {
    position: absolute;
    top: 50%;
    left: 50%;
    transform: translate(-50%, -50%);
  }

  .halo {
    position: absolute;
    top: 50%;
    left: 50%;
    transform: translate(-50%, -50%);
    border-radius: 50%;
    background-color: rgba(0, 128, 255, 0.4);
    transition: width 0.1s ease, height 0.1s ease, opacity 0.1s ease;
    opacity: 0;
  }

  .device-info {
    font-size: 14px;
    margin: 10px 0;
    color: #555;
    font-weight: bold;
  }

  .debug-container {
    width: 90%;
    max-width: 800px;
    background: #f0f0f0;
    border: 1px solid #ccc;
    border-radius: 5px;
    padding: 10px;
    text-align: left;
    overflow-y: auto;
    height: 150px;
    color: #555;
  }

  .debug-message {
    font-size: 12px;
    font-family: monospace;
    margin: 0;
    padding: 0;
    white-space: pre-wrap;
  }
</style>
</head>
<body>
<div class="microphone-container">
  <div class="halo" id="halo"></div>
  <svg fill="#000000" height="150px" width="100px" version="1.1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" xmlns:xlink="http://www.w3.org/1999/xlink" enable-background="new 0 0 512 512">
    <g>
      <g>
        <path d="m439.5,236c0-11.3-9.1-20.4-20.4-20.4s-20.4,9.1-20.4,20.4c0,70-64,126.9-142.7,126.9-78.7,0-142.7-56.9-142.7-126.9 0-11.3-9.1-20.4-20.4-20.4s-20.4,9.1-20.4,20.4c0,86.2 71.5,157.4 163.1,166.7v57.5h-23.6c-11.3,0-20.4,9.1-20.4,20.4 0,11.3 9.1,20.4 20.4,20.4h88c11.3,0 20.4-9.1 20.4-20.4 0-11.3-9.1-20.4-20.4-20.4h-23.6v-57.5c91.6-9.3 163.1-80.5 163.1-166.7z"/>
        <path d="m256,323.5c51,0 92.3-41.3 92.3-92.3v-127.9c0-51-41.3-92.3-92.3-92.3s-92.3,41.3-92.3,92.3v127.9c0,51 41.3,92.3 92.3,92.3zm-52.3-220.2c0-28.8 23.5-52.3 52.3-52.3s52.3,23.5 52.3,52.3v127.9c0,28.8-23.5,52.3-52.3,52.3s-52.3-23.5-52.3-52.3v-127.9z"/>
      </g>
    </g>
  </svg>
</div>
<p class="device-info" id="device-info">Detecting input device...</p>
<div class="debug-container" id="debug-container">
  <p class="debug-message">Debug Log:</p>
</div>

<script>
window.onload = async function () {
  const debugContainer = document.getElementById('debug-container');
  const deviceInfoLabel = document.getElementById('device-info');
  const halo = document.getElementById('halo');
  const audioQueue = [];
  const retryInterval = 300;

  function logDebug(message) {
    const logMessage = document.createElement('p');
    logMessage.textContent = message;
    logMessage.className = 'debug-message';
    debugContainer.appendChild(logMessage);
    debugContainer.scrollTop = debugContainer.scrollHeight;
    console.log(message);
  }

  if (!navigator.mediaDevices || !window.AudioContext) {
    logDebug('Error: Your browser does not support the required audio APIs.');
    alert('Your browser does not support the required audio APIs.');
    return;
  }

  try {
    const devices = await navigator.mediaDevices.enumerateDevices();
    const audioInputDevices = devices.filter(device => device.kind === 'audioinput');

    if (audioInputDevices.length > 0) {
      const selectedDevice = audioInputDevices[0];
      deviceInfoLabel.textContent = `Input Device: ${selectedDevice.label} (ID: ${selectedDevice.deviceId})`;
    } else {
      deviceInfoLabel.textContent = 'No audio input devices detected.';
    }
  } catch (error) {
    deviceInfoLabel.textContent = 'Error detecting input devices.';
    logDebug(`Error: ${error.message}`);
    return;
  }

  const audioContext = new AudioContext({ sampleRate: 24000 });

  navigator.mediaDevices.getUserMedia({ audio: true })
    .then((stream) => {
      logDebug('Microphone access granted.');
      const source = audioContext.createMediaStreamSource(stream);
      const processor = audioContext.createScriptProcessor(4096, 1, 1);

      source.connect(processor);
      processor.connect(audioContext.destination);

      processor.onaudioprocess = function (audioProcessingEvent) {
        const inputBuffer = audioProcessingEvent.inputBuffer;
        const inputData = inputBuffer.getChannelData(0);

        const rms = Math.sqrt(inputData.reduce((sum, val) => sum + val * val, 0) / inputData.length);
        const scaledVolume = Math.min(rms * 10, 1);
        halo.style.width = `${100 + scaledVolume * 100}px`;
        halo.style.height = `${100 + scaledVolume * 100}px`;
        halo.style.opacity = scaledVolume;

        const pcmSamples = new Int16Array(inputData.map(sample => Math.max(-1, Math.min(1, sample)) * 32767));
        const byteArray = new Uint8Array(pcmSamples.buffer);
        const base64Data = btoa(String.fromCharCode(...byteArray));

        audioQueue.push(base64Data);
        logDebug(`Audio package queued: ${base64Data.substring(0, 30)}...`);
        processQueue();
      };
      logDebug('Recording started. Speak into your microphone.');
    })
    .catch((error) => {
      logDebug(`Error: Could not access the microphone. Details: ${error.message}`);
      alert('Could not access your microphone. Please check your permissions.');
    });

  async function processQueue() {
    if (audioQueue.length === 0) return;

    const payload = { audioPackages: [...audioQueue] };
    try {
      // const response = await fetch('http://127.0.0.1:8000/process-audio', {
        const response = await fetch('http://localhost:8888/audio2.php', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(payload),
      });

      if (response.status === 200) {
        logDebug('Audio packages sent successfully.');
        audioQueue.length = 0; // Clear queue on success
        const result = await response.json();
        if (result.audioPackages) {
          playAudio(result.audioPackages);
        }
      } else if (response.status === 429) {
        logDebug('Backend returned 429. Retrying in 300ms...');
        setTimeout(processQueue, retryInterval);
      } else {
        logDebug(`Unexpected response status: ${response.status}`);
      }
    } catch (error) {
      logDebug(`Error sending audio: ${error.message}`);
    }
  }

  async function playAudio(audioPackages) {
    for (const base64Audio of audioPackages) {
      const audioBuffer = Uint8Array.from(atob(base64Audio), c => c.charCodeAt(0));
      const pcmAudio = new Int16Array(audioBuffer.buffer);
      const audioData = audioContext.createBuffer(1, pcmAudio.length, 24000);
      const audioChannel = audioData.getChannelData(0);

      for (let i = 0; i < pcmAudio.length; i++) {
        audioChannel[i] = pcmAudio[i] / 32768;
      }

      const source = audioContext.createBufferSource();
      source.buffer = audioData;
      source.connect(audioContext.destination);
      source.start();
      logDebug('Audio played back successfully.');
    }
  }
};
</script>
</body>
</html>